{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "import os\n",
    "import random\n",
    "import itertools\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "from scipy import stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Parameters\n",
    "# PATHs\n",
    "RESULTS_DIR = \"../results\"\n",
    "\n",
    "# Plotting\n",
    "width = 800\n",
    "height = 600\n",
    "scale = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Miscellaneous Functions\n",
    "# START: COPIED FROM https://stackoverflow.com/questions/30069846/how-to-find-out-chinese-or-japanese-character-in-a-string-in-python\n",
    "ranges = [\n",
    "    {\"from\": ord(\"\\u3300\"), \"to\": ord(\"\\u33ff\")},  # compatibility ideographs\n",
    "    {\"from\": ord(\"\\ufe30\"), \"to\": ord(\"\\ufe4f\")},  # compatibility ideographs\n",
    "    {\"from\": ord(\"\\uf900\"), \"to\": ord(\"\\ufaff\")},  # compatibility ideographs\n",
    "    {\"from\": ord(\"\\U0002F800\"), \"to\": ord(\"\\U0002fa1f\")},  # compatibility ideographs\n",
    "    {\"from\": ord(\"\\u3040\"), \"to\": ord(\"\\u309f\")},  # Japanese Hiragana\n",
    "    {\"from\": ord(\"\\u30a0\"), \"to\": ord(\"\\u30ff\")},  # Japanese Katakana\n",
    "    {\"from\": ord(\"\\u2e80\"), \"to\": ord(\"\\u2eff\")},  # cjk radicals supplement\n",
    "    {\"from\": ord(\"\\u4e00\"), \"to\": ord(\"\\u9fff\")},\n",
    "    {\"from\": ord(\"\\u3400\"), \"to\": ord(\"\\u4dbf\")},\n",
    "    {\"from\": ord(\"\\U00020000\"), \"to\": ord(\"\\U0002a6df\")},\n",
    "    {\"from\": ord(\"\\U0002a700\"), \"to\": ord(\"\\U0002b73f\")},\n",
    "    {\"from\": ord(\"\\U0002b740\"), \"to\": ord(\"\\U0002b81f\")},\n",
    "    {\"from\": ord(\"\\U0002b820\"), \"to\": ord(\"\\U0002ceaf\")},  # included as of Unicode 8.0\n",
    "]\n",
    "\n",
    "\n",
    "def is_cjk(char):\n",
    "    return any([range[\"from\"] <= ord(char) <= range[\"to\"] for range in ranges])\n",
    "\n",
    "\n",
    "def cjk_substrings(string):\n",
    "    i = 0\n",
    "    while i < len(string):\n",
    "        if is_cjk(string[i]):\n",
    "            start = i\n",
    "            while is_cjk(string[i]):\n",
    "                i += 1\n",
    "            yield string[start:i]\n",
    "        i += 1\n",
    "\n",
    "\n",
    "# END: COPIED FROM https://stackoverflow.com/questions/30069846/how-to-find-out-chinese-or-japanese-character-in-a-string-in-python\n",
    "\n",
    "\n",
    "def set_default(obj):\n",
    "    if isinstance(obj, set):\n",
    "        return list(obj)\n",
    "    raise TypeError\n",
    "\n",
    "\n",
    "def longest_continuous_common_subsequence(list1, list2):\n",
    "    max_length = 0\n",
    "\n",
    "    for i in range(len(list1)):\n",
    "        for j in range(len(list2)):\n",
    "            temp_length = 0\n",
    "            # Check how long the sequence is starting from list1[i] and list2[j]\n",
    "            while (\n",
    "                i + temp_length < len(list1)\n",
    "                and j + temp_length < len(list2)\n",
    "                and list1[i + temp_length] == list2[j + temp_length]\n",
    "            ):\n",
    "                temp_length += 1\n",
    "            # Update max_length if a longer sequence is found\n",
    "            max_length = max(max_length, temp_length)\n",
    "\n",
    "    return max_length\n",
    "\n",
    "\n",
    "def remove_text_inside_quotes(text):\n",
    "    return re.sub(r\"\\\".*?\\\"\", \"\", text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Correlation Analysis (Section 6.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Load performance metrics\n",
    "# Full Performance Scores\n",
    "tab_large = {\n",
    "    \"data\": {\n",
    "        0: \"One-Shot ($1$)\",\n",
    "        1: \"Few-Shot ($10$)\",\n",
    "        2: \"Few-Shot ($100$)\",\n",
    "        3: \"Few-Shot ($1000$)\",\n",
    "        4: \"Full-Shot ($2473$)\",\n",
    "        5: \"English\",\n",
    "        6: \"Full ($4946$)\",\n",
    "    },\n",
    "    \"rouge\": {0: 0.161, 1: 0.18, 2: 0.421, 3: 0.451, 4: 0.461, 5: 0.454, 6: 0.536},\n",
    "    \"meteor\": {0: 0.116, 1: 0.135, 2: 0.258, 3: 0.376, 4: 0.388, 5: 0.399, 6: 0.489},\n",
    "    \"bleurt\": {0: -0.631, 1: -0.597, 2: -0.21, 3: 0.057, 4: 0.04, 5: 0.057, 6: 0.161},\n",
    "    \"comparison\": {\n",
    "        0: 0.822,\n",
    "        1: 0.857,\n",
    "        2: 0.962,\n",
    "        3: 0.984,\n",
    "        4: 0.984,\n",
    "        5: 0.981,\n",
    "        6: 0.978,\n",
    "    },\n",
    "    \"fluency\": {0: 1.073, 1: 1.092, 2: 3.72, 3: 4.022, 4: 4.067, 5: 4.221, 6: 3.867},\n",
    "    \"accuracy\": {0: 3.981, 1: 4.011, 2: 4.642, 3: 4.704, 4: 4.747, 5: 4.771, 6: 4.763},\n",
    "    \"model\": {\n",
    "        0: \"large\",\n",
    "        1: \"large\",\n",
    "        2: \"large\",\n",
    "        3: \"large\",\n",
    "        4: \"large\",\n",
    "        5: \"large\",\n",
    "        6: \"large\",\n",
    "    },\n",
    "}\n",
    "tab_base = {\n",
    "    \"data\": {\n",
    "        0: \"One-Shot ($1$)\",\n",
    "        1: \"Few-Shot ($10$)\",\n",
    "        2: \"Few-Shot ($100$)\",\n",
    "        3: \"Few-Shot ($1000$)\",\n",
    "        4: \"Full-Shot ($2473$)\",\n",
    "        5: \"English ($2473$)\",\n",
    "        6: \"Full ($4946$)\",\n",
    "    },\n",
    "    \"rouge\": {0: 0.184, 1: 0.178, 2: 0.377, 3: 0.438, 4: 0.45, 5: 0.458, 6: 0.499},\n",
    "    \"meteor\": {0: 0.151, 1: 0.152, 2: 0.315, 3: 0.353, 4: 0.366, 5: 0.398, 6: 0.448},\n",
    "    \"bleurt\": {0: -0.552, 1: -0.578, 2: -0.014, 3: 0.025, 4: 0.032, 5: 0.072, 6: 0.122},\n",
    "    \"comparison\": {\n",
    "        0: 0.838,\n",
    "        1: 0.819,\n",
    "        2: 0.962,\n",
    "        3: 0.981,\n",
    "        4: 0.984,\n",
    "        5: 0.984,\n",
    "        6: 0.994,\n",
    "    },\n",
    "    \"fluency\": {0: 1.256, 1: 1.181, 2: 3.929, 3: 4.073, 4: 3.99, 5: 4.13, 6: 4.25},\n",
    "    \"accuracy\": {0: 3.871, 1: 3.989, 2: 4.642, 3: 4.717, 4: 4.712, 5: 4.771, 6: 4.733},\n",
    "    \"model\": {\n",
    "        0: \"base\",\n",
    "        1: \"base\",\n",
    "        2: \"base\",\n",
    "        3: \"base\",\n",
    "        4: \"base\",\n",
    "        5: \"base\",\n",
    "        6: \"base\",\n",
    "    },\n",
    "}\n",
    "tab_small = {\n",
    "    \"data\": {\n",
    "        0: \"One-Shot ($1$)\",\n",
    "        1: \"Few-Shot ($10$)\",\n",
    "        2: \"Few-Shot ($100$)\",\n",
    "        3: \"Few-Shot ($1000$)\",\n",
    "        4: \"Full-Shot ($2473$)\",\n",
    "        5: \"English ($2473$)\",\n",
    "        6: \"Full ($4946$)\",\n",
    "    },\n",
    "    \"rouge\": {0: 0.216, 1: 0.227, 2: 0.306, 3: 0.421, 4: 0.429, 5: 0.444, 6: 0.468},\n",
    "    \"meteor\": {0: 0.203, 1: 0.22, 2: 0.235, 3: 0.325, 4: 0.333, 5: 0.363, 6: 0.403},\n",
    "    \"bleurt\": {0: -0.48, 1: -0.336, 2: -0.183, 3: 0.001, 4: 0.009, 5: 0.045, 6: 0.083},\n",
    "    \"comparison\": {\n",
    "        0: 0.852,\n",
    "        1: 0.881,\n",
    "        2: 0.884,\n",
    "        3: 0.946,\n",
    "        4: 0.962,\n",
    "        5: 0.968,\n",
    "        6: 0.976,\n",
    "    },\n",
    "    \"fluency\": {0: 3.232, 1: 3.288, 2: 3.536, 3: 3.604, 4: 3.773, 5: 3.855, 6: 3.841},\n",
    "    \"accuracy\": {0: 4.051, 1: 4.105, 2: 4.057, 3: 4.553, 4: 4.604, 5: 4.714, 6: 4.73},\n",
    "    \"model\": {\n",
    "        0: \"small\",\n",
    "        1: \"small\",\n",
    "        2: \"small\",\n",
    "        3: \"small\",\n",
    "        4: \"small\",\n",
    "        5: \"small\",\n",
    "        6: \"small\",\n",
    "    },\n",
    "}\n",
    "\n",
    "# Load as Pandas Dataframe\n",
    "tab_large = pd.DataFrame(tab_large)\n",
    "tab_base = pd.DataFrame(tab_base)\n",
    "tab_small = pd.DataFrame(tab_small)\n",
    "tab_large[\"model\"] = \"large\"\n",
    "tab_base[\"model\"] = \"base\"\n",
    "tab_small[\"model\"] = \"small\"\n",
    "\n",
    "# Extract and rename columns\n",
    "table = pd.concat(\n",
    "    [\n",
    "        tab_large[\n",
    "            [\"rouge\", \"meteor\", \"bleurt\", \"comparison\", \"fluency\", \"accuracy\", \"model\"]\n",
    "        ],\n",
    "        tab_base[\n",
    "            [\"rouge\", \"meteor\", \"bleurt\", \"comparison\", \"fluency\", \"accuracy\", \"model\"]\n",
    "        ],\n",
    "        tab_small[\n",
    "            [\"rouge\", \"meteor\", \"bleurt\", \"comparison\", \"fluency\", \"accuracy\", \"model\"]\n",
    "        ],\n",
    "    ]\n",
    ").reset_index()\n",
    "table = table[\n",
    "    [\"rouge\", \"meteor\", \"bleurt\", \"comparison\", \"fluency\", \"accuracy\", \"model\"]\n",
    "]\n",
    "table.columns = [\n",
    "    \"ROUGE-L\",\n",
    "    \"METEOR\",\n",
    "    \"BLEURT\",\n",
    "    \"Comparison\",\n",
    "    \"Fluency\",\n",
    "    \"Accuracy\",\n",
    "    \"Model\",\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Generate Plots\n",
    "# Miscellaneous (color pads and metric names to loop through)\n",
    "color_map = {\"large\": \"red\", \"base\": \"blue\", \"small\": \"green\"}\n",
    "colors = table[\"Model\"].map(color_map)\n",
    "automated = [\"ROUGE-L\", \"METEOR\", \"BLEURT\"]\n",
    "prompting = [\"Comparison\", \"Fluency\", \"Accuracy\"]\n",
    "\n",
    "for a_m in automated:\n",
    "    for p_m in prompting:\n",
    "        correlation = np.round(stats.spearmanr(table[a_m], table[p_m]).statistic, 3)\n",
    "        fig = go.Figure()\n",
    "        fig = px.scatter(table, x=a_m, y=p_m, color=\"Model\", trendline=\"ols\")\n",
    "\n",
    "        width = 600\n",
    "        height = 400\n",
    "        scale = 1\n",
    "\n",
    "        fig.update_layout(\n",
    "            width=width * scale,\n",
    "            height=height * scale,\n",
    "            font=dict(size=20 * scale),\n",
    "            xaxis_title=a_m,\n",
    "            yaxis_title=f\"Prompt {p_m}\",\n",
    "            margin=dict(l=0, r=10, t=50, b=0),\n",
    "            legend=dict(x=0.8, y=0.05, bordercolor=\"Black\", borderwidth=1),\n",
    "            title=f\"Spearman Correlation: {correlation}\",\n",
    "            title_x=0.5,\n",
    "            barmode=\"overlay\",\n",
    "            plot_bgcolor=\"white\",\n",
    "        )\n",
    "\n",
    "        fig.update_traces(marker=dict(size=12), selector=dict(mode=\"markers\"))\n",
    "\n",
    "        fig.update_xaxes(\n",
    "            mirror=True,\n",
    "            ticks=\"outside\",\n",
    "            showline=True,\n",
    "            linecolor=\"black\",\n",
    "            gridcolor=\"lightgrey\",\n",
    "        )\n",
    "        fig.update_yaxes(\n",
    "            mirror=True,\n",
    "            ticks=\"outside\",\n",
    "            showline=True,\n",
    "            linecolor=\"black\",\n",
    "            gridcolor=\"lightgrey\",\n",
    "        )\n",
    "\n",
    "        fig.show()\n",
    "        fig.write_image(f\"{a_m}_{p_m}.pdf\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Explanation Statistics (Section 6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Get data statistics\n",
    "# Load CSV files\n",
    "gold = pd.read_csv(\n",
    "    \"../results/mt0-base-language=ja-epochs=15-batch_size=4-shots=10/fluency_results.csv\"\n",
    ")[\"gold_output\"]\n",
    "large = pd.read_csv(\n",
    "    \"../results/mt0-base-language=ja-epochs=15-batch_size=4-shots=10/fluency_results.csv\"\n",
    ")[\"output\"]\n",
    "base = pd.read_csv(\n",
    "    \"../results/mt0-large-language=ja-epochs=15-batch_size=4-shots=10/fluency_results.csv\"\n",
    ")[\"output\"]\n",
    "small = pd.read_csv(\n",
    "    \"../results/mt0-small-language=ja-epochs=15-batch_size=4-shots=10/fluency_results.csv\"\n",
    ")[\"output\"]\n",
    "\n",
    "# Get lengths of explanations\n",
    "gold_len = [len(i.split()) - 1 for i in gold]\n",
    "large_len = [len(i.split()) - 1 for i in large]\n",
    "base_len = [len(i.split()) - 1 for i in base]\n",
    "small_len = [len(i.split()) - 1 for i in small]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Generate plots\n",
    "fig = go.Figure()\n",
    "fig.add_trace(go.Histogram(x=gold_len, name=\"Ground Truth\"))\n",
    "fig.add_trace(go.Histogram(x=large_len, name=\"large\"))\n",
    "fig.add_trace(go.Histogram(x=base_len, name=\"base\"))\n",
    "fig.add_trace(go.Histogram(x=small_len, name=\"small\"))\n",
    "\n",
    "fig.update_layout(\n",
    "    width=width * scale,\n",
    "    height=height * scale,\n",
    "    font=dict(size=20 * scale),\n",
    "    xaxis_title=\"Explanation Length\",\n",
    "    yaxis_title=\"Count\",\n",
    "    margin=dict(l=0, r=10, t=10, b=0),\n",
    "    legend=dict(x=0.75, y=0.97, bordercolor=\"Black\", borderwidth=1),\n",
    ")\n",
    "\n",
    "fig.update_layout(plot_bgcolor=\"white\")\n",
    "fig.update_traces(marker={\"opacity\": 0.85})\n",
    "\n",
    "fig.update_xaxes(\n",
    "    mirror=True,\n",
    "    ticks=\"outside\",\n",
    "    showline=True,\n",
    "    linecolor=\"black\",\n",
    "    gridcolor=\"lightgrey\",\n",
    ")\n",
    "fig.update_yaxes(\n",
    "    mirror=True,\n",
    "    ticks=\"outside\",\n",
    "    showline=True,\n",
    "    linecolor=\"black\",\n",
    "    gridcolor=\"lightgrey\",\n",
    ")\n",
    "\n",
    "\n",
    "fig.show()\n",
    "fig.write_image(\"explanation_lengths.pdf\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get Sample Explanations (Section 6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = pd.read_csv(\n",
    "    \"../results/mt0-base-language=en-epochs=15-batch_size=4/fluency_results.csv\"\n",
    ")[\"input\"]\n",
    "\n",
    "index = random.randint(0, len(text))\n",
    "\n",
    "gold = pd.read_csv(\n",
    "    \"../results/mt0-base-language=en-epochs=15-batch_size=4/fluency_results.csv\"\n",
    ")[\"gold_output\"]\n",
    "large = pd.read_csv(\n",
    "    \"../results/mt0-base-language=en-epochs=15-batch_size=4/fluency_results.csv\"\n",
    ")[\"output\"]\n",
    "base = pd.read_csv(\n",
    "    \"../results/mt0-large-language=en-epochs=15-batch_size=4/fluency_results.csv\"\n",
    ")[\"output\"]\n",
    "small = pd.read_csv(\n",
    "    \"../results/mt0-small-language=en-epochs=15-batch_size=4/fluency_results.csv\"\n",
    ")[\"output\"]\n",
    "\n",
    "print(\n",
    "    \"# Input: \",\n",
    "    text[index],\n",
    ")\n",
    "print(\n",
    "    \"# Ground Truth: \",\n",
    "    gold[index],\n",
    ")\n",
    "print(\n",
    "    \"# mt0-large: \",\n",
    "    large[index],\n",
    ")\n",
    "print(\n",
    "    \"# mt0-base: \",\n",
    "    base[index],\n",
    ")\n",
    "print(\"# mt0-small: \", small[index])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Word Overlap Count (Section 6.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Get statistics\n",
    "model_to_overlap = {}\n",
    "\n",
    "for folder in os.listdir(RESULTS_DIR):\n",
    "    if \"mt0\" in folder:\n",
    "        if \"shots\" in folder:\n",
    "            file = os.path.join(\n",
    "                RESULTS_DIR, folder, os.listdir(os.path.join(RESULTS_DIR, folder))[0]\n",
    "            )\n",
    "\n",
    "            model_size = file.split(\"-\")[1]\n",
    "            shots = file.split(\"=\")[-1].split(\"/\")[0]\n",
    "\n",
    "            if model_size not in model_to_overlap:\n",
    "                model_to_overlap[model_size] = {}\n",
    "\n",
    "            model_to_overlap[model_size][shots] = []\n",
    "            df = pd.read_csv(file)\n",
    "\n",
    "            for index, row in df.iterrows():\n",
    "                input_text = row[\"input\"].lower().split()[1:]\n",
    "                output_text = row[\"output\"].lower().split()[1:]\n",
    "\n",
    "                overlapping_count = longest_continuous_common_subsequence(\n",
    "                    input_text, output_text\n",
    "                )\n",
    "                model_to_overlap[model_size][shots].append(overlapping_count)\n",
    "\n",
    "        elif \"language=en\" in folder:\n",
    "            file = os.path.join(\n",
    "                RESULTS_DIR, folder, os.listdir(os.path.join(RESULTS_DIR, folder))[0]\n",
    "            )\n",
    "            df = pd.read_csv(file)\n",
    "\n",
    "            model_size = file.split(\"-\")[1]\n",
    "            if model_size not in model_to_overlap:\n",
    "                model_to_overlap[model_size] = {}\n",
    "\n",
    "            if \"arguments\" not in folder:\n",
    "                label_name = \"Native (English Split)\"\n",
    "            elif \"arguments\" in folder:\n",
    "                label_name = \"Native (Full Split)\"\n",
    "\n",
    "            model_to_overlap[model_size][label_name] = []\n",
    "\n",
    "            for index, row in df.iterrows():\n",
    "                input_text = row[\"input\"].lower().split()[1:]\n",
    "                output_text = row[\"output\"].lower().split()[1:]\n",
    "\n",
    "                overlapping_count = longest_continuous_common_subsequence(\n",
    "                    input_text, output_text\n",
    "                )\n",
    "                model_to_overlap[model_size][label_name].append(overlapping_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Generate Box Plots for overlap statistics\n",
    "fig = go.Figure()\n",
    "\n",
    "models = [\"small\", \"base\", \"large\"]\n",
    "shots = [\"1\", \"10\", \"100\", \"1000\", \"full\", \"Native\"]\n",
    "\n",
    "# Create figures\n",
    "for model_size in models:\n",
    "    xs = list(\n",
    "        itertools.chain.from_iterable(\n",
    "            [i for i in model_to_overlap[model_size].values()]\n",
    "        )\n",
    "    )\n",
    "    ys = list(\n",
    "        itertools.chain.from_iterable(\n",
    "            [[i] * 100 for i in model_to_overlap[model_size].keys()]\n",
    "        )\n",
    "    )\n",
    "\n",
    "    fig.add_trace(\n",
    "        go.Box(\n",
    "            y=xs,\n",
    "            x=ys,\n",
    "            name=f\"{model_size}\",\n",
    "        )\n",
    "    )\n",
    "\n",
    "# Get overlap statistics for ground truth\n",
    "ground_truth_overlap = []\n",
    "\n",
    "for index, row in df.iterrows():\n",
    "    input_text = row[\"input\"].lower().split()[1:]\n",
    "    output_text = row[\"gold_output\"].lower().split()[1:]\n",
    "\n",
    "    overlapping_count = longest_continuous_common_subsequence(input_text, output_text)\n",
    "    overlapping_ratio = overlapping_count / len(output_text)\n",
    "\n",
    "    ground_truth_overlap.append(overlapping_count)\n",
    "\n",
    "fig.add_trace(\n",
    "    go.Box(\n",
    "        y=ground_truth_overlap,\n",
    "        x=[\"Ground Truth\"] * len(ground_truth_overlap),\n",
    "        name=\"Ground Truth\",\n",
    "    )\n",
    ")\n",
    "\n",
    "\n",
    "fig.update_layout(barmode=\"overlay\", yaxis_range=[0, 20], plot_bgcolor=\"white\")\n",
    "\n",
    "fig.update_xaxes(\n",
    "    mirror=True,\n",
    "    ticks=\"outside\",\n",
    "    showline=True,\n",
    "    linecolor=\"black\",\n",
    "    gridcolor=\"lightgrey\",\n",
    ")\n",
    "fig.update_yaxes(\n",
    "    mirror=True,\n",
    "    ticks=\"outside\",\n",
    "    showline=True,\n",
    "    linecolor=\"black\",\n",
    "    gridcolor=\"lightgrey\",\n",
    ")\n",
    "\n",
    "fig.update_layout(boxmode=\"group\")\n",
    "\n",
    "fig.update_layout(\n",
    "    width=width * scale,\n",
    "    height=height * scale,\n",
    "    font=dict(size=20 * scale),\n",
    "    xaxis_title=\"Number of Shots\",\n",
    "    yaxis_title=\"Overlap Ratio with Input Text\",\n",
    "    margin=dict(l=0, r=10, t=10, b=0),\n",
    "    legend=dict(x=0.84, y=0.97, bordercolor=\"Black\", borderwidth=1),\n",
    ")\n",
    "\n",
    "\n",
    "fig.update_traces(orientation=\"v\")\n",
    "fig.update_layout(boxgroupgap=0.2, boxgap=0)\n",
    "\n",
    "fig.show()\n",
    "fig.write_image(\"word_overlap.pdf\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset Statistics (Section 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Get text lengths for English split\n",
    "en_train = pd.read_csv(\"../data/training_lang=en-data=split_en.csv\")\n",
    "\n",
    "en_train_input = [\n",
    "    len(i.split(\"[TEXT]: \")[-1].split(\"[EMOTION]: \")[0].split())\n",
    "    for i in en_train[\"input\"]\n",
    "]\n",
    "en_train_output = [\n",
    "    len(i.split(\"[RATIONALE]: \")[-1].split()) for i in en_train[\"output\"]\n",
    "]\n",
    "\n",
    "fig = go.Figure()\n",
    "fig.add_trace(go.Histogram(x=en_train_input, name=\"Text\"))\n",
    "fig.add_trace(go.Histogram(x=en_train_output, name=\"Explanation\"))\n",
    "\n",
    "fig.update_layout(\n",
    "    width=width * scale,\n",
    "    height=height * scale,\n",
    "    font=dict(size=20 * scale),\n",
    "    xaxis_title=\"Document Length\",\n",
    "    yaxis_title=\"Count\",\n",
    "    margin=dict(l=0, r=10, t=10, b=0),\n",
    "    legend=dict(x=0.67, y=0.97, bordercolor=\"Black\", borderwidth=1),\n",
    ")\n",
    "\n",
    "fig.update_layout(barmode=\"overlay\", plot_bgcolor=\"white\")\n",
    "fig.update_traces(overwrite=True, marker={\"opacity\": 0.7})\n",
    "\n",
    "fig.update_xaxes(\n",
    "    mirror=True,\n",
    "    ticks=\"outside\",\n",
    "    showline=True,\n",
    "    linecolor=\"black\",\n",
    "    gridcolor=\"lightgrey\",\n",
    ")\n",
    "fig.update_yaxes(\n",
    "    mirror=True,\n",
    "    ticks=\"outside\",\n",
    "    showline=True,\n",
    "    linecolor=\"black\",\n",
    "    gridcolor=\"lightgrey\",\n",
    ")\n",
    "\n",
    "fig.show()\n",
    "fig.write_image(\"en_train.pdf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Get text lengths for Japanese split\n",
    "ja_train = pd.read_csv(\"../data/training_lang=ja-data=split_ja.csv\")\n",
    "ja_train_input = [\n",
    "    len(i.split(\"[文章]: \")[-1].split(\"[感情]: \")[0]) for i in ja_train[\"input\"]\n",
    "]\n",
    "ja_train_output = [len(i.split(\"[説明]: \")[-1]) for i in ja_train[\"output\"]]\n",
    "\n",
    "fig = go.Figure()\n",
    "fig.add_trace(go.Histogram(x=ja_train_input, name=\"Text\"))\n",
    "fig.add_trace(go.Histogram(x=ja_train_output, name=\"Explanation\"))\n",
    "\n",
    "fig.update_layout(\n",
    "    width=width * scale,\n",
    "    height=height * scale,\n",
    "    font=dict(size=20 * scale),\n",
    "    xaxis_title=\"Document Length\",\n",
    "    yaxis_title=\"Count\",\n",
    "    margin=dict(l=0, r=10, t=10, b=0),\n",
    "    legend=dict(x=0.67, y=0.97, bordercolor=\"Black\", borderwidth=1),\n",
    ")\n",
    "\n",
    "fig.update_layout(barmode=\"overlay\", plot_bgcolor=\"white\")\n",
    "fig.update_traces(overwrite=True, marker={\"opacity\": 0.7})\n",
    "\n",
    "fig.update_xaxes(\n",
    "    mirror=True,\n",
    "    ticks=\"outside\",\n",
    "    showline=True,\n",
    "    linecolor=\"black\",\n",
    "    gridcolor=\"lightgrey\",\n",
    ")\n",
    "fig.update_yaxes(\n",
    "    mirror=True,\n",
    "    ticks=\"outside\",\n",
    "    showline=True,\n",
    "    linecolor=\"black\",\n",
    "    gridcolor=\"lightgrey\",\n",
    ")\n",
    "\n",
    "fig.show()\n",
    "fig.write_image(\"ja_train.pdf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Get text lengths for untranslated Japanese split\n",
    "json_data = json.load(open(\"../data/lang=en-data=full.json\", \"r\"))\n",
    "json_en_data = json.load(open(\"../data/lang=en-data=split_en.json\", \"r\"))\n",
    "ja_untranslated = [i for i in json_data if i not in json_en_data]\n",
    "ja_untranslated = pd.DataFrame(ja_untranslated)[[\"text\", \"choice\", \"explanation\"]]\n",
    "\n",
    "ja_untranslated_train_input = [len(i.split()) for i in ja_untranslated[\"text\"]]\n",
    "ja_untranslated_train_output = [len(i.split()) for i in ja_untranslated[\"explanation\"]]\n",
    "\n",
    "fig = go.Figure()\n",
    "fig.add_trace(go.Histogram(x=ja_untranslated_train_input, name=\"Text\"))\n",
    "fig.add_trace(go.Histogram(x=ja_untranslated_train_output, name=\"Explanation\"))\n",
    "\n",
    "fig.update_layout(\n",
    "    width=width * scale,\n",
    "    height=height * scale,\n",
    "    font=dict(size=20 * scale),\n",
    "    xaxis_title=\"Document Length\",\n",
    "    yaxis_title=\"Count\",\n",
    "    margin=dict(l=0, r=10, t=10, b=0),\n",
    "    legend=dict(x=0.67, y=0.97, bordercolor=\"Black\", borderwidth=1),\n",
    ")\n",
    "\n",
    "fig.update_layout(barmode=\"overlay\", plot_bgcolor=\"white\")\n",
    "fig.update_traces(overwrite=True, marker={\"opacity\": 0.7})\n",
    "\n",
    "fig.update_xaxes(\n",
    "    mirror=True,\n",
    "    ticks=\"outside\",\n",
    "    showline=True,\n",
    "    linecolor=\"black\",\n",
    "    gridcolor=\"lightgrey\",\n",
    ")\n",
    "fig.update_yaxes(\n",
    "    mirror=True,\n",
    "    ticks=\"outside\",\n",
    "    showline=True,\n",
    "    linecolor=\"black\",\n",
    "    gridcolor=\"lightgrey\",\n",
    ")\n",
    "\n",
    "\n",
    "fig.show()\n",
    "fig.write_image(\"ja_untranslated_train.pdf\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
