{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = pd.read_csv(\"../results/mt0-small-language=ja-epochs=15-batch_size=4-shots=full/fluency_results.csv\")\n",
    "df = pd.read_csv(\n",
    "    \"../results/mt0-small-language=ja-epochs=15-batch_size=4/fluency_results.csv\"\n",
    ")\n",
    "\n",
    "# np.round(np.mean([int(i) for i in list(df[\"fluency\"]) if i.isdigit()]), 3)\n",
    "np.round(np.mean(list(df[\"fluency\"])), 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from astropy.table import Table\n",
    "\n",
    "tab_large = Table.read(\"mt0-large.tex\").to_pandas()\n",
    "tab_base = Table.read(\"mt0-base.tex\").to_pandas()\n",
    "tab_small = Table.read(\"mt0-small.tex\").to_pandas()\n",
    "\n",
    "tab_large.columns = [\n",
    "    \"data\",\n",
    "    \"rouge\",\n",
    "    \"meteor\",\n",
    "    \"bleurt\",\n",
    "    \"comparison\",\n",
    "    \"fluency\",\n",
    "    \"accuracy\",\n",
    "]\n",
    "tab_base.columns = [\n",
    "    \"data\",\n",
    "    \"rouge\",\n",
    "    \"meteor\",\n",
    "    \"bleurt\",\n",
    "    \"comparison\",\n",
    "    \"fluency\",\n",
    "    \"accuracy\",\n",
    "]\n",
    "tab_small.columns = [\n",
    "    \"data\",\n",
    "    \"rouge\",\n",
    "    \"meteor\",\n",
    "    \"bleurt\",\n",
    "    \"comparison\",\n",
    "    \"fluency\",\n",
    "    \"accuracy\",\n",
    "]\n",
    "\n",
    "tab_large[\"model\"] = \"large\"\n",
    "tab_base[\"model\"] = \"base\"\n",
    "tab_small[\"model\"] = \"small\"\n",
    "\n",
    "table = pd.concat(\n",
    "    [\n",
    "        tab_large[\n",
    "            [\"rouge\", \"meteor\", \"bleurt\", \"comparison\", \"fluency\", \"accuracy\", \"model\"]\n",
    "        ],\n",
    "        tab_base[\n",
    "            [\"rouge\", \"meteor\", \"bleurt\", \"comparison\", \"fluency\", \"accuracy\", \"model\"]\n",
    "        ],\n",
    "        tab_small[\n",
    "            [\"rouge\", \"meteor\", \"bleurt\", \"comparison\", \"fluency\", \"accuracy\", \"model\"]\n",
    "        ],\n",
    "    ]\n",
    ").reset_index()\n",
    "table = table[\n",
    "    [\"rouge\", \"meteor\", \"bleurt\", \"comparison\", \"fluency\", \"accuracy\", \"model\"]\n",
    "]\n",
    "table.columns = [\n",
    "    \"ROUGE-L\",\n",
    "    \"METEOR\",\n",
    "    \"BLEURT\",\n",
    "    \"Comparison\",\n",
    "    \"Fluency\",\n",
    "    \"Accuracy\",\n",
    "    \"Model\",\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import stats\n",
    "\n",
    "print(\n",
    "    np.round(stats.spearmanr(table[\"ROUGE-L\"], table[\"Comparison\"]).statistic, 3),\n",
    "    np.round(stats.spearmanr(table[\"ROUGE-L\"], table[\"Fluency\"]).statistic, 3),\n",
    "    np.round(stats.spearmanr(table[\"ROUGE-L\"], table[\"Accuracy\"]).statistic, 3),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "color_map = {\"large\": \"red\", \"base\": \"blue\", \"small\": \"green\"}\n",
    "colors = table[\"Model\"].map(color_map)\n",
    "\n",
    "automated = [\"ROUGE-L\", \"METEOR\", \"BLEURT\"]\n",
    "prompting = [\"Comparison\", \"Fluency\", \"Accuracy\"]\n",
    "\n",
    "for a_m in automated:\n",
    "    for p_m in prompting:\n",
    "        correlation = np.round(stats.spearmanr(table[a_m], table[p_m]).statistic, 3)\n",
    "        fig = go.Figure()\n",
    "        fig = px.scatter(table, x=a_m, y=p_m, color=\"Model\", trendline=\"ols\")\n",
    "\n",
    "        width = 600\n",
    "        height = 400\n",
    "        scale = 1\n",
    "\n",
    "        fig.update_layout(\n",
    "            width=width * scale,\n",
    "            height=height * scale,\n",
    "            font=dict(size=20 * scale),\n",
    "            xaxis_title=a_m,\n",
    "            yaxis_title=f\"Prompt {p_m}\",\n",
    "            margin=dict(l=0, r=10, t=50, b=0),\n",
    "            legend=dict(x=0.8, y=0.05, bordercolor=\"Black\", borderwidth=1),\n",
    "        )\n",
    "\n",
    "        fig.update_traces(marker=dict(size=12), selector=dict(mode=\"markers\"))\n",
    "\n",
    "        fig.update_layout(\n",
    "            title=f\"Spearman Correlation: {correlation}\",\n",
    "            title_x=0.5,\n",
    "            barmode=\"overlay\",\n",
    "            plot_bgcolor=\"white\",\n",
    "        )\n",
    "\n",
    "        fig.update_xaxes(\n",
    "            mirror=True,\n",
    "            ticks=\"outside\",\n",
    "            showline=True,\n",
    "            linecolor=\"black\",\n",
    "            gridcolor=\"lightgrey\",\n",
    "        )\n",
    "        fig.update_yaxes(\n",
    "            mirror=True,\n",
    "            ticks=\"outside\",\n",
    "            showline=True,\n",
    "            linecolor=\"black\",\n",
    "            gridcolor=\"lightgrey\",\n",
    "        )\n",
    "\n",
    "        fig.show()\n",
    "        fig.write_image(f\"{a_m}_{p_m}.pdf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "color_map = {\"large\": \"red\", \"base\": \"blue\", \"small\": \"green\"}\n",
    "colors = table[\"Model\"].map(color_map)\n",
    "\n",
    "fig = go.Figure()\n",
    "\n",
    "\n",
    "fig = px.scatter(\n",
    "    table,\n",
    "    x=\"METEOR\",\n",
    "    y=\"Comparison\",\n",
    "    color=\"Model\",\n",
    "    trendline=\"ols\",\n",
    ")\n",
    "\n",
    "width = 600\n",
    "height = 400\n",
    "scale = 1\n",
    "\n",
    "fig.update_layout(\n",
    "    width=width * scale,\n",
    "    height=height * scale,\n",
    "    font=dict(size=20 * scale),\n",
    "    xaxis_title=\"METEOR\",\n",
    "    yaxis_title=\"Prompt Comparison\",\n",
    "    margin=dict(l=0, r=10, t=10, b=0),\n",
    "    legend=dict(x=0.8, y=0.05, bordercolor=\"Black\", borderwidth=1),\n",
    ")\n",
    "\n",
    "fig.update_traces(marker=dict(size=12), selector=dict(mode=\"markers\"))\n",
    "\n",
    "fig.update_layout(barmode=\"overlay\", plot_bgcolor=\"white\")\n",
    "\n",
    "fig.update_xaxes(\n",
    "    mirror=True,\n",
    "    ticks=\"outside\",\n",
    "    showline=True,\n",
    "    linecolor=\"black\",\n",
    "    gridcolor=\"lightgrey\",\n",
    ")\n",
    "fig.update_yaxes(\n",
    "    mirror=True,\n",
    "    ticks=\"outside\",\n",
    "    showline=True,\n",
    "    linecolor=\"black\",\n",
    "    gridcolor=\"lightgrey\",\n",
    ")\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "color_map = {\"large\": \"red\", \"base\": \"blue\", \"small\": \"green\"}\n",
    "colors = table[\"Model\"].map(color_map)\n",
    "\n",
    "fig = go.Figure()\n",
    "\n",
    "\n",
    "fig = px.scatter(\n",
    "    table,\n",
    "    x=\"BLEURT\",\n",
    "    y=\"Comparison\",\n",
    "    color=\"Model\",\n",
    "    trendline=\"ols\",\n",
    ")\n",
    "\n",
    "width = 600\n",
    "height = 400\n",
    "scale = 1\n",
    "\n",
    "fig.update_layout(\n",
    "    width=width * scale,\n",
    "    height=height * scale,\n",
    "    font=dict(size=20 * scale),\n",
    "    xaxis_title=\"BLEURT\",\n",
    "    yaxis_title=\"Prompt Comparison\",\n",
    "    margin=dict(l=0, r=10, t=10, b=0),\n",
    "    legend=dict(x=0.8, y=0.05, bordercolor=\"Black\", borderwidth=1),\n",
    ")\n",
    "\n",
    "fig.update_traces(marker=dict(size=12), selector=dict(mode=\"markers\"))\n",
    "\n",
    "fig.update_layout(barmode=\"overlay\", plot_bgcolor=\"white\")\n",
    "\n",
    "fig.update_xaxes(\n",
    "    mirror=True,\n",
    "    ticks=\"outside\",\n",
    "    showline=True,\n",
    "    linecolor=\"black\",\n",
    "    gridcolor=\"lightgrey\",\n",
    ")\n",
    "fig.update_yaxes(\n",
    "    mirror=True,\n",
    "    ticks=\"outside\",\n",
    "    showline=True,\n",
    "    linecolor=\"black\",\n",
    "    gridcolor=\"lightgrey\",\n",
    ")\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "color_map = {\"large\": \"red\", \"base\": \"blue\", \"small\": \"green\"}\n",
    "colors = table[\"Model\"].map(color_map)\n",
    "\n",
    "fig = go.Figure()\n",
    "\n",
    "fig = px.scatter(\n",
    "    table,\n",
    "    x=\"ROUGE-L\",\n",
    "    y=\"Comparison\",\n",
    "    color=\"Model\",\n",
    "    trendline=\"ols\",\n",
    ")\n",
    "\n",
    "width = 600\n",
    "height = 400\n",
    "scale = 1\n",
    "\n",
    "fig.update_layout(\n",
    "    width=width * scale,\n",
    "    height=height * scale,\n",
    "    font=dict(size=20 * scale),\n",
    "    xaxis_title=\"ROUGE-L\",\n",
    "    yaxis_title=\"Prompt Comparison\",\n",
    "    margin=dict(l=0, r=10, t=10, b=0),\n",
    "    legend=dict(x=0.8, y=0.05, bordercolor=\"Black\", borderwidth=1),\n",
    ")\n",
    "\n",
    "fig.update_traces(marker=dict(size=12), selector=dict(mode=\"markers\"))\n",
    "\n",
    "fig.update_layout(barmode=\"overlay\", plot_bgcolor=\"white\")\n",
    "\n",
    "fig.update_xaxes(\n",
    "    mirror=True,\n",
    "    ticks=\"outside\",\n",
    "    showline=True,\n",
    "    linecolor=\"black\",\n",
    "    gridcolor=\"lightgrey\",\n",
    ")\n",
    "fig.update_yaxes(\n",
    "    mirror=True,\n",
    "    ticks=\"outside\",\n",
    "    showline=True,\n",
    "    linecolor=\"black\",\n",
    "    gridcolor=\"lightgrey\",\n",
    ")\n",
    "\n",
    "fig.show()\n",
    "fig.write_image(\"rouge_comparison.pdf\")\n",
    "fig.write_image(\"rouge_comparison.pdf\")\n",
    "fig.write_image(\"rouge_comparison.pdf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "color_map = {\"large\": \"red\", \"base\": \"blue\", \"small\": \"green\"}\n",
    "colors = table[\"Model\"].map(color_map)\n",
    "\n",
    "fig = go.Figure()\n",
    "\n",
    "fig = px.scatter(\n",
    "    table,\n",
    "    x=\"ROUGE-L\",\n",
    "    y=\"Fluency\",\n",
    "    color=\"Model\",\n",
    "    trendline=\"ols\",\n",
    ")\n",
    "\n",
    "width = 600\n",
    "height = 400\n",
    "scale = 1\n",
    "\n",
    "fig.update_layout(\n",
    "    width=width * scale,\n",
    "    height=height * scale,\n",
    "    font=dict(size=20 * scale),\n",
    "    xaxis_title=\"ROUGE-L\",\n",
    "    yaxis_title=\"Prompt Fluency\",\n",
    "    margin=dict(l=0, r=10, t=10, b=0),\n",
    "    legend=dict(x=0.8, y=0.05, bordercolor=\"Black\", borderwidth=1),\n",
    ")\n",
    "\n",
    "fig.update_traces(marker=dict(size=12), selector=dict(mode=\"markers\"))\n",
    "\n",
    "fig.update_layout(barmode=\"overlay\", plot_bgcolor=\"white\")\n",
    "\n",
    "fig.update_xaxes(\n",
    "    mirror=True,\n",
    "    ticks=\"outside\",\n",
    "    showline=True,\n",
    "    linecolor=\"black\",\n",
    "    gridcolor=\"lightgrey\",\n",
    ")\n",
    "fig.update_yaxes(\n",
    "    mirror=True,\n",
    "    ticks=\"outside\",\n",
    "    showline=True,\n",
    "    linecolor=\"black\",\n",
    "    gridcolor=\"lightgrey\",\n",
    ")\n",
    "\n",
    "fig.show()\n",
    "fig.write_image(\"rouge_fluency.pdf\")\n",
    "fig.write_image(\"rouge_fluency.pdf\")\n",
    "fig.write_image(\"rouge_fluency.pdf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "color_map = {\"large\": \"red\", \"base\": \"blue\", \"small\": \"green\"}\n",
    "colors = table[\"Model\"].map(color_map)\n",
    "\n",
    "fig = go.Figure()\n",
    "\n",
    "fig = px.scatter(\n",
    "    table,\n",
    "    x=\"ROUGE-L\",\n",
    "    y=\"Accuracy\",\n",
    "    color=\"Model\",\n",
    "    trendline=\"ols\",\n",
    ")\n",
    "\n",
    "width = 600\n",
    "height = 400\n",
    "scale = 1\n",
    "\n",
    "fig.update_layout(\n",
    "    width=width * scale,\n",
    "    height=height * scale,\n",
    "    font=dict(size=20 * scale),\n",
    "    xaxis_title=\"ROUGE-L\",\n",
    "    yaxis_title=\"Prompt Accuracy\",\n",
    "    margin=dict(l=0, r=10, t=10, b=0),\n",
    "    legend=dict(x=0.8, y=0.05, bordercolor=\"Black\", borderwidth=1),\n",
    ")\n",
    "\n",
    "fig.update_traces(marker=dict(size=12), selector=dict(mode=\"markers\"))\n",
    "\n",
    "fig.update_layout(barmode=\"overlay\", plot_bgcolor=\"white\")\n",
    "\n",
    "fig.update_xaxes(\n",
    "    mirror=True,\n",
    "    ticks=\"outside\",\n",
    "    showline=True,\n",
    "    linecolor=\"black\",\n",
    "    gridcolor=\"lightgrey\",\n",
    ")\n",
    "fig.update_yaxes(\n",
    "    mirror=True,\n",
    "    ticks=\"outside\",\n",
    "    showline=True,\n",
    "    linecolor=\"black\",\n",
    "    gridcolor=\"lightgrey\",\n",
    ")\n",
    "\n",
    "fig.show()\n",
    "fig.write_image(\"rouge_accuracy.pdf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\n",
    "    \"../results/mt0-small-language=ja-epochs=15-batch_size=4-shots=10/fluency_results.csv\"\n",
    ")\n",
    "\n",
    "filtered_scores = []\n",
    "for index, row in df.iterrows():\n",
    "    # try:\n",
    "    #     output = row[\"fluency\"]\n",
    "\n",
    "    #     text = output.replace(\"[RATIONALE 1]\", \"\").replace(\"[RATIONALE 2]\", \"\")\n",
    "    #     scores = (re.findall(r'\\d+', text))\n",
    "    #     if scores == []:\n",
    "    #         if [i for i in cjk_substrings(row[\"output\"])] == []:\n",
    "    #             continue\n",
    "    #         else:\n",
    "    #             scores = 0\n",
    "    #     else:\n",
    "    #         scores = min(scores)\n",
    "    #     filtered_scores.append(int(scores))\n",
    "    # except IndexError:\n",
    "    #     continue\n",
    "    output = row[\"fluency\"]\n",
    "\n",
    "    text = output.replace(\"[RATIONALE 1]\", \"\").replace(\"[RATIONALE 2]\", \"\")\n",
    "    scores = re.findall(r\"\\d+\", text)\n",
    "    if scores == []:\n",
    "        if [i for i in cjk_substrings(row[\"output\"])] == []:\n",
    "            continue\n",
    "        else:\n",
    "            scores = 0\n",
    "    else:\n",
    "        scores = min(scores)\n",
    "    filtered_scores.append(int(scores))\n",
    "\n",
    "print(len(filtered_scores), np.round(np.mean(filtered_scores), 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = json.load(open(\"../data/lang=en-data=full.json\", \"r\"))\n",
    "\n",
    "inputs = []\n",
    "outputs = []\n",
    "\n",
    "for item in data:\n",
    "    text_input = \"[TEXT]: {} [EMOTION]: \".format(item[\"text\"], item[\"choice\"])\n",
    "    text_output = \"[RATIONALE]: {}\".format(item[\"explanation\"])\n",
    "\n",
    "    inputs.append(text_input)\n",
    "    outputs.append(text_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame()\n",
    "df[\"input\"] = inputs\n",
    "df[\"output\"] = outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(\"../data/lang=en-data=full.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(json.load(open(\"../data/lang=en-data=full.json\", \"r\"))).to_csv(\n",
    "    \"../data/lang=en-data=full.csv\", index=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "comparison = pd.read_csv(\n",
    "    \"../results/mt0-small-language=en-epochs=15-batch_size=4-arguments=full_data/comparison_results.csv\"\n",
    ")\n",
    "# automated = pd.read_csv(\"../results/mt0-base-language=en-epochs=15-batch_size=4-arguments=full_data/results_all.csv\")\n",
    "\n",
    "print(\n",
    "    sum(comparison[\"comparison\"] == \"YES\") / len(comparison),\n",
    "    sum(comparison[\"comparison\"] == \"NO\") / len(comparison),\n",
    ")\n",
    "# print(np.mean(automated[\"bleurt\"]), np.mean(automated[\"rouge\"]), np.mean(automated[\"meteor\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -*- coding:utf-8 -*-\n",
    "ranges = [\n",
    "    {\"from\": ord(\"\\u3300\"), \"to\": ord(\"\\u33ff\")},  # compatibility ideographs\n",
    "    {\"from\": ord(\"\\ufe30\"), \"to\": ord(\"\\ufe4f\")},  # compatibility ideographs\n",
    "    {\"from\": ord(\"\\uf900\"), \"to\": ord(\"\\ufaff\")},  # compatibility ideographs\n",
    "    {\"from\": ord(\"\\U0002F800\"), \"to\": ord(\"\\U0002fa1f\")},  # compatibility ideographs\n",
    "    {\"from\": ord(\"\\u3040\"), \"to\": ord(\"\\u309f\")},  # Japanese Hiragana\n",
    "    {\"from\": ord(\"\\u30a0\"), \"to\": ord(\"\\u30ff\")},  # Japanese Katakana\n",
    "    {\"from\": ord(\"\\u2e80\"), \"to\": ord(\"\\u2eff\")},  # cjk radicals supplement\n",
    "    {\"from\": ord(\"\\u4e00\"), \"to\": ord(\"\\u9fff\")},\n",
    "    {\"from\": ord(\"\\u3400\"), \"to\": ord(\"\\u4dbf\")},\n",
    "    {\"from\": ord(\"\\U00020000\"), \"to\": ord(\"\\U0002a6df\")},\n",
    "    {\"from\": ord(\"\\U0002a700\"), \"to\": ord(\"\\U0002b73f\")},\n",
    "    {\"from\": ord(\"\\U0002b740\"), \"to\": ord(\"\\U0002b81f\")},\n",
    "    {\"from\": ord(\"\\U0002b820\"), \"to\": ord(\"\\U0002ceaf\")},  # included as of Unicode 8.0\n",
    "]\n",
    "\n",
    "\n",
    "def is_cjk(char):\n",
    "    return any([range[\"from\"] <= ord(char) <= range[\"to\"] for range in ranges])\n",
    "\n",
    "\n",
    "def cjk_substrings(string):\n",
    "    i = 0\n",
    "    while i < len(string):\n",
    "        if is_cjk(string[i]):\n",
    "            start = i\n",
    "            while is_cjk(string[i]):\n",
    "                i += 1\n",
    "            yield string[start:i]\n",
    "        i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "comparison = pd.read_csv(\n",
    "    \"../results/mt0-small-language=en-epochs=15-batch_size=4/comparison_results.csv\"\n",
    ")\n",
    "\n",
    "\n",
    "for index, row in comparison.iterrows():\n",
    "    try:\n",
    "        if len([i for i in cjk_substrings(row[\"output\"].replace(\"[説明]:\", \"\"))]) != 0:\n",
    "            comparison.at[index, \"comparison\"] = \"NO\"\n",
    "    except IndexError:\n",
    "        comparison.at[index, \"comparison\"] = \"NO\"\n",
    "\n",
    "np.round(sum(comparison[\"comparison\"] == \"YES\") / len(comparison), 3), np.round(\n",
    "    sum(comparison[\"comparison\"] == \"NO\") / len(comparison), 3\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.mean(automated[\"bleurt\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_dir = \"mt0-small-language=en-epochs=15-batch_size=4-arguments=full_data\"\n",
    "\n",
    "print(\n",
    "    np.round(\n",
    "        np.mean(pd.read_csv(f\"../results/{file_dir}/results_all.csv\")[\"bleurt\"]), 3\n",
    "    ),\n",
    "    np.round(\n",
    "        np.mean(pd.read_csv(f\"../results/{file_dir}/results_all.csv\")[\"rouge\"]), 3\n",
    "    ),\n",
    "    np.round(\n",
    "        np.mean(pd.read_csv(f\"../results/{file_dir}/results_all.csv\")[\"meteor\"]), 3\n",
    "    ),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\n",
    "    # np.mean(pd.read_csv(\"../results/mt0-large-language=ja-epochs=15-batch_size=4-shots=100/results.csv\")[\"bleurt\"]),\n",
    "    np.mean(\n",
    "        pd.read_csv(\n",
    "            \"../results/mt0-large-language=ja-epochs=15-batch_size=4-shots=full/results.csv\"\n",
    "        )[\"rouge\"]\n",
    "    ),\n",
    "    np.mean(\n",
    "        pd.read_csv(\n",
    "            \"../results/mt0-large-language=ja-epochs=15-batch_size=4-shots=full/results.csv\"\n",
    "        )[\"meteor\"]\n",
    "    ),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_data = json.load(open(\"../data/lang=en-data=full.json\", \"r\"))\n",
    "en_data = json.load(open(\"../data/lang=en-data=split_en.json\", \"r\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sampled_en_data = random.sample(full_data, 500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for index, i in enumerate(sampled_en_data):\n",
    "    i[\"translation_id\"] = index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "js_data = [i for i in full_data if i not in en_data]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "json.dump(\n",
    "    sampled_en_data, open(\"../data/lang=en-data=emotion_test.json\", \"w\"), indent=4\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from munch import Munch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Munch.fromDict({\"model\": {\"tokenizer\": \"a\", \"checkpoint\": \"b\"}}).model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "en_labels = pd.read_csv(\"../results/emotion_check/mt0-large-lang=en.csv\")\n",
    "ja_labels = pd.read_csv(\"../results/emotion_check/mt0-large-lang=ja.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_labels = pd.DataFrame()\n",
    "all_labels[\"input\"] = en_labels[\"input\"]\n",
    "all_labels[\"en\"] = en_labels[\"output\"]\n",
    "all_labels[\"ground_truth\"] = en_labels[\"gold_output\"]\n",
    "all_labels[\"ja\"] = ja_labels[\"output\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(ja_labels[\"output\"]), len(en_labels[\"output\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "en_data = json.load(open(\"../data/lang=en-data=emotion_test.json\", \"r\"))\n",
    "ja_data = json.load(open(\"../data/lang=ja-data=emotion_test.json\", \"r\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(ja_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[[\"text\", \"choice\", \"translation_id\"]].to_csv(\"temp.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.read_csv(\"temp.csv\").iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = []\n",
    "\n",
    "for index, row in pd.read_csv(\"temp.csv\").iterrows():\n",
    "    data.append(\n",
    "        {\n",
    "            \"text\": row[\"text\"],\n",
    "            \"choice\": row[\"choice\"],\n",
    "            \"translation_id\": row[\"translation_id\"],\n",
    "        }\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "json.dump(data, open(\"../data/lang=ja-data=emotion_test.json\", \"w\"), indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "en_labels = pd.read_csv(\"../results/emotion_check/mt0-large-lang=en.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ja_labels = pd.read_csv(\"../results/emotion_check/mt0-large-lang=ja.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plutchik_en_to_ja = {\n",
    "    \"joy\": \"喜び\",\n",
    "    \"trust\": \"信頼\",\n",
    "    \"fear\": \"恐れ\",\n",
    "    \"sadness\": \"悲しみ\",\n",
    "    \"disgust\": \"嫌悪\",\n",
    "    \"anger\": \"怒り\",\n",
    "    \"anticipation\": \"期待\",\n",
    "}\n",
    "inv_map = {v: k for k, v in plutchik_en_to_ja.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for index, row in ja_labels.iterrows():\n",
    "    if ja_labels.at[index, \"output\"] in [\"哀悼\", \"悲伤\", \"悲劇\", \"悲喜\", \"悲痛\", \"悲观\", \"痛感\"]:\n",
    "        new_em = \"sadness\"\n",
    "    elif ja_labels.at[index, \"output\"] == \"喜好\":\n",
    "        new_em = \"joy\"\n",
    "    elif ja_labels.at[index, \"output\"] == \"嫌惡\":\n",
    "        new_em = \"disgust\"\n",
    "    elif ja_labels.at[index, \"output\"] in [\"喜\", \"感受\", \"感激\"]:\n",
    "        new_em = \"joy\"\n",
    "    elif ja_labels.at[index, \"output\"] in [\"害怕\", \"恐怖心\", \"恐慌\", \"恐怖\", \"恐懼\"]:\n",
    "        new_em = \"fear\"\n",
    "    elif ja_labels.at[index, \"output\"] == [\"希望\", \"自信\"]:\n",
    "        new_em = \"anticipation\"\n",
    "    elif ja_labels.at[index, \"output\"] in list(plutchik_en_to_ja.values()):\n",
    "        new_em = inv_map[ja_labels.at[index, \"output\"]]\n",
    "\n",
    "    ja_labels.at[index, \"output\"] = new_em"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "set(en_labels[\"output\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "en_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "en_label = json.load(\n",
    "    open(\"../results/emotion_check/prompting-lang=en-data=emotion_test.json\", \"r\")\n",
    ")\n",
    "\n",
    "for item in en_label:\n",
    "    item[\"model_label\"] = item[\"model_label\"].lower()\n",
    "    if item[\"model_label\"] in list(plutchik_en_to_ja.keys()):\n",
    "        continue\n",
    "    else:\n",
    "        emotions = []\n",
    "        for emotion in list(plutchik_en_to_ja.keys()):\n",
    "            if emotion in item[\"model_label\"]:\n",
    "                emotions.append(emotion)\n",
    "        item[\"model_label\"] = \", \".join(emotions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ja_label = json.load(\n",
    "    open(\"../results/emotion_check/prompting-lang=ja-data=emotion_test.json\", \"r\")\n",
    ")\n",
    "\n",
    "for item in ja_label:\n",
    "    if item[\"model_label\"] in list(inv_map.keys()):\n",
    "        item[\"model_label\"] = inv_map[item[\"model_label\"]]\n",
    "    else:\n",
    "        emotions = []\n",
    "        for emotion in list(inv_map.keys()):\n",
    "            if emotion in item[\"model_label\"]:\n",
    "                emotions.append(inv_map[emotion])\n",
    "        item[\"model_label\"] = \", \".join(emotions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "positive_emotions = [\"joy\", \"trust\", \"anticipation\"]\n",
    "negative_emotions = [\"fear\", \"sadness\", \"disgust\", \"anger\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for item in en_label:\n",
    "    if item[\"model_label\"] == \"\":\n",
    "        item[\"general_label\"] = \"missing\"\n",
    "    else:\n",
    "        for emotion in positive_emotions:\n",
    "            if emotion in item[\"model_label\"]:\n",
    "                item[\"general_label\"] = \"negative\"\n",
    "            else:\n",
    "                item[\"general_label\"] = \"positive\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for item in ja_label:\n",
    "    if item[\"model_label\"] == \"\":\n",
    "        item[\"general_label\"] = \"missing\"\n",
    "    else:\n",
    "        for emotion in positive_emotions:\n",
    "            if emotion in item[\"model_label\"]:\n",
    "                item[\"general_label\"] = \"negative\"\n",
    "            else:\n",
    "                item[\"general_label\"] = \"positive\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "en_label_df = pd.DataFrame.from_records(en_label)\n",
    "ja_label_df = pd.DataFrame.from_records(ja_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_label_df = pd.DataFrame()\n",
    "full_label_df[\"text\"] = en_label_df[\"text\"]\n",
    "full_label_df[\"en\"] = en_label_df[\"model_label\"]\n",
    "full_label_df[\"ja\"] = ja_label_df[\"model_label\"]\n",
    "full_label_df[\"en_general\"] = en_label_df[\"general_label\"]\n",
    "full_label_df[\"ja_general\"] = ja_label_df[\"general_label\"]\n",
    "full_label_df[\"ground_truth\"] = en_label_df[\"ground_truth\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "same = []\n",
    "for index, row in full_label_df.iterrows():\n",
    "    en_emotions = row[\"en\"].split(\", \")\n",
    "    ja_emotions = row[\"ja\"].split(\", \")\n",
    "\n",
    "    row_label = False\n",
    "\n",
    "    if en_emotions == [\"\"] or ja_emotions == [\"\"]:\n",
    "        row_label = -1\n",
    "\n",
    "    for i in en_emotions:\n",
    "        for j in ja_emotions:\n",
    "            if i == j:\n",
    "                row_label = True\n",
    "\n",
    "    same.append(row_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "same_general = []\n",
    "for index, row in full_label_df.iterrows():\n",
    "    row_label = False\n",
    "\n",
    "    if row[\"en_general\"] == \"missing\" or ja_emotions == \"missing\":\n",
    "        row_label = -1\n",
    "\n",
    "    if row[\"en_general\"] == row[\"ja_general\"]:\n",
    "        row_label = True\n",
    "\n",
    "    same_general.append(row_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_label_df[\"same\"] = same\n",
    "full_label_df[\"same_general\"] = same_general"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(full_label_df[full_label_df[\"same\"] == -1]), len(\n",
    "    full_label_df[full_label_df[\"same\"] == True]\n",
    "), len(full_label_df[full_label_df[\"same\"] == False])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(full_label_df[full_label_df[\"same_general\"] == True]), len(\n",
    "    full_label_df[full_label_df[\"same_general\"] == False]\n",
    "), len(full_label_df[full_label_df[\"same_general\"] == -1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_label_df[full_label_df[\"en_general\"] == \"missing\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.graph_objects as go\n",
    "\n",
    "en_train = pd.read_csv(\"../data/training_lang=en-data=split_en.csv\")\n",
    "en_train_input = [\n",
    "    len(i.split(\"[TEXT]: \")[-1].split(\"[EMOTION]: \")[0].split())\n",
    "    for i in en_train[\"input\"]\n",
    "]\n",
    "en_train_output = [\n",
    "    len(i.split(\"[RATIONALE]: \")[-1].split()) for i in en_train[\"output\"]\n",
    "]\n",
    "\n",
    "width = 600\n",
    "height = 400\n",
    "scale = 1\n",
    "\n",
    "fig = go.Figure()\n",
    "fig.add_trace(go.Histogram(x=en_train_input, name=\"Text\"))\n",
    "fig.add_trace(go.Histogram(x=en_train_output, name=\"Explanation\"))\n",
    "\n",
    "fig.update_layout(\n",
    "    width=width * scale,\n",
    "    height=height * scale,\n",
    "    font=dict(size=20 * scale),\n",
    "    xaxis_title=\"Document Length\",\n",
    "    yaxis_title=\"Count\",\n",
    "    margin=dict(l=0, r=10, t=10, b=0),\n",
    "    legend=dict(x=0.67, y=0.97, bordercolor=\"Black\", borderwidth=1),\n",
    ")\n",
    "\n",
    "fig.update_layout(barmode=\"overlay\", plot_bgcolor=\"white\")\n",
    "fig.update_traces(overwrite=True, marker={\"opacity\": 0.7})\n",
    "\n",
    "fig.update_xaxes(\n",
    "    mirror=True,\n",
    "    ticks=\"outside\",\n",
    "    showline=True,\n",
    "    linecolor=\"black\",\n",
    "    gridcolor=\"lightgrey\",\n",
    ")\n",
    "fig.update_yaxes(\n",
    "    mirror=True,\n",
    "    ticks=\"outside\",\n",
    "    showline=True,\n",
    "    linecolor=\"black\",\n",
    "    gridcolor=\"lightgrey\",\n",
    ")\n",
    "\n",
    "\n",
    "fig.show()\n",
    "fig.write_image(\"en_train.pdf\")\n",
    "fig.write_image(\"en_train.pdf\")\n",
    "fig.write_image(\"en_train.pdf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "width = 600\n",
    "height = 400\n",
    "scale = 1\n",
    "\n",
    "ja_train = pd.read_csv(\"../data/training_lang=ja-data=split_ja.csv\")\n",
    "ja_train_input = [\n",
    "    len(i.split(\"[文章]: \")[-1].split(\"[感情]: \")[0]) for i in ja_train[\"input\"]\n",
    "]\n",
    "ja_train_output = [len(i.split(\"[説明]: \")[-1]) for i in ja_train[\"output\"]]\n",
    "\n",
    "fig = go.Figure()\n",
    "fig.add_trace(go.Histogram(x=ja_train_input, name=\"Text\"))\n",
    "fig.add_trace(go.Histogram(x=ja_train_output, name=\"Explanation\"))\n",
    "\n",
    "fig.update_layout(\n",
    "    width=width * scale,\n",
    "    height=height * scale,\n",
    "    font=dict(size=20 * scale),\n",
    "    xaxis_title=\"Document Length\",\n",
    "    yaxis_title=\"Count\",\n",
    "    margin=dict(l=0, r=10, t=10, b=0),\n",
    "    legend=dict(x=0.67, y=0.97, bordercolor=\"Black\", borderwidth=1),\n",
    ")\n",
    "\n",
    "fig.update_layout(barmode=\"overlay\", plot_bgcolor=\"white\")\n",
    "fig.update_traces(overwrite=True, marker={\"opacity\": 0.7})\n",
    "\n",
    "fig.update_xaxes(\n",
    "    mirror=True,\n",
    "    ticks=\"outside\",\n",
    "    showline=True,\n",
    "    linecolor=\"black\",\n",
    "    gridcolor=\"lightgrey\",\n",
    ")\n",
    "fig.update_yaxes(\n",
    "    mirror=True,\n",
    "    ticks=\"outside\",\n",
    "    showline=True,\n",
    "    linecolor=\"black\",\n",
    "    gridcolor=\"lightgrey\",\n",
    ")\n",
    "\n",
    "\n",
    "fig.show()\n",
    "fig.write_image(\"ja_train.pdf\")\n",
    "fig.write_image(\"ja_train.pdf\")\n",
    "fig.write_image(\"ja_train.pdf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "json_data = json.load(open(\"../data/lang=en-data=full.json\", \"r\"))\n",
    "json_en_data = json.load(open(\"../data/lang=en-data=split_en.json\", \"r\"))\n",
    "ja_untranslated = [i for i in json_data if i not in json_en_data]\n",
    "ja_untranslated = pd.DataFrame(ja_untranslated)[[\"text\", \"choice\", \"explanation\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "width = 600\n",
    "height = 400\n",
    "scale = 1\n",
    "\n",
    "json_data = json.load(open(\"../data/lang=en-data=full.json\", \"r\"))\n",
    "json_en_data = json.load(open(\"../data/lang=en-data=split_en.json\", \"r\"))\n",
    "ja_untranslated = [i for i in json_data if i not in json_en_data]\n",
    "ja_untranslated = pd.DataFrame(ja_untranslated)[[\"text\", \"choice\", \"explanation\"]]\n",
    "\n",
    "ja_untranslated_train_input = [len(i.split()) for i in ja_untranslated[\"text\"]]\n",
    "ja_untranslated_train_output = [len(i.split()) for i in ja_untranslated[\"explanation\"]]\n",
    "\n",
    "fig = go.Figure()\n",
    "fig.add_trace(go.Histogram(x=ja_untranslated_train_input, name=\"Text\"))\n",
    "fig.add_trace(go.Histogram(x=ja_untranslated_train_output, name=\"Explanation\"))\n",
    "\n",
    "fig.update_layout(\n",
    "    width=width * scale,\n",
    "    height=height * scale,\n",
    "    font=dict(size=20 * scale),\n",
    "    xaxis_title=\"Document Length\",\n",
    "    yaxis_title=\"Count\",\n",
    "    margin=dict(l=0, r=10, t=10, b=0),\n",
    "    legend=dict(x=0.67, y=0.97, bordercolor=\"Black\", borderwidth=1),\n",
    ")\n",
    "\n",
    "fig.update_layout(barmode=\"overlay\", plot_bgcolor=\"white\")\n",
    "fig.update_traces(overwrite=True, marker={\"opacity\": 0.7})\n",
    "\n",
    "fig.update_xaxes(\n",
    "    mirror=True,\n",
    "    ticks=\"outside\",\n",
    "    showline=True,\n",
    "    linecolor=\"black\",\n",
    "    gridcolor=\"lightgrey\",\n",
    ")\n",
    "fig.update_yaxes(\n",
    "    mirror=True,\n",
    "    ticks=\"outside\",\n",
    "    showline=True,\n",
    "    linecolor=\"black\",\n",
    "    gridcolor=\"lightgrey\",\n",
    ")\n",
    "\n",
    "\n",
    "fig.show()\n",
    "fig.write_image(\"ja_untranslated_train.pdf\")\n",
    "fig.write_image(\"ja_untranslated_train.pdf\")\n",
    "fig.write_image(\"ja_untranslated_train.pdf\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
